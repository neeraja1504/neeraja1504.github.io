---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
Iâ€™m Neeraja Kirtane, my research is focused on building trustworthy and interpretable language models. My work lies at the intersection of AI safety, robustness, and interpretability, with the goal of making large language models (LLMs) more reliable and transparent. 

Iâ€™m currently a Research Engineer at **[MathGPT.ai](https://mathgpt.ai)**, where Iâ€™m developing education-centric reasoning benchmarks to evaluate reasoning robustness in state-of-the-art models. My [work](https://arxiv.org/pdf/2510.06430?) explores how simple linguistic or contextual changes can destabilize model reasoning â€” and how fine-tuning small language models (SLMs) can improve their consistency and usefulness in AI tutoring and educational applications.

Alongside this, I am working under the supervision of **[Prof. Kuan-Hao Huang](https://khhuang.me/)** at Texas A&M University to probe reasoning and multilingual generalization in LLMs. Using interpretability tools such as neuron activation analysis and feature attribution, we are studying how models encode reasoning processes across languages and how these representations transfer between linguistic systems.

Before this, I completed my M.S. in Computer Science at the University of Illinois Urbanaâ€“Champaign (UIUC), where I was advised by [Prof. Hao Peng](https://haopeng-nlp.github.io/) and [Prof. Dilek Hakkani-TÃ¼r](https://siebelschool.illinois.edu/about/people/all-faculty/dilek).
At UIUC, I worked on projects aimed at improving trust and accountability in LLMs:

- **[FactCheckmate](https://arxiv.org/pdf/2410.02899)** â€“ a framework for preemptively detecting and mitigating hallucinations in LLMs by analyzing their hidden-state dynamics and identifying early indicators of factual inconsistency.

-**[Jailbreaking LLMs](https://arxiv.org/pdf/2501.14073)** â€“ a study of scientific-sounding adversarial prompts that can elicit biased or toxic model responses, revealing deeper vulnerabilities in instruction-following and safety alignment.



<!-- Iâ€™m **Neeraja Kirtane**, a recent **MSCS graduate** from the University of Illinois Urbana-Champaign (UIUC), where I was advised by [Prof. Hao Peng](https://haopeng-nlp.github.io/) and [Prof. Dilek Hakkani-TÃ¼r](https://siebelschool.illinois.edu/about/people/all-faculty/dilek).

My research focuses on building **trustworthy and interpretable NLP systems**. At UIUC, I worked on:

- **[FactCheckmate](https://arxiv.org/pdf/2410.02899)**: Preemptively detecting and mitigating hallucinations in large language models (LLMs) by analyzing their hidden states.
- **[Jailbreaking LLMs](https://arxiv.org/pdf/2501.14073)**: Designing scientific-sounding prompts that elicit biased or toxic responses from LLMs, revealing vulnerabilities in instruction following.

Currently, I am:
- Collaborating with **[Prof. Kuan-Hao Huang](https://khhuang.me/)** (Texas A&M University) on probing reasoning in **multilingual LLMs** using interpretability tools.
- Interning at **[MathGPT.ai](https://mathgpt.ai)**, where Iâ€™m developing a **benchmark** to evaluate the reasoning robustness of SOTA models and fine-tuning **small language models (SLMs)** for AI tutoring needs and applications.

Previously, I was a **Post-Baccalaureate Research Fellow** at the [Robert Bosch Centre for Data Science and AI (RBCDSAI)](https://rbcdsai.iitm.ac.in/) at **IIT Madras**, advised by [Prof. Balaraman Ravindran](http://www.cse.iitm.ac.in/~ravi/), where I built intelligent tools to generate Wikipedia biographies for women in STEM. -->

Iâ€™m currently seeking **PhD opportunities** or **full-time research roles** in _AI safety, robustness, and interpretability_.

If youâ€™re interested in my work or would like to collaborate, feel free to reach out via [Email](mailto:kirtane3@illinois.edu) or [LinkedIn](https://www.linkedin.com/in/neeraja-kirtane-16353b2a/). You can also view my [CV](neeraja1504/neeraja1504.github.io/files/NeerajaKiranKirtane_CV_Oct_2025.pdf) for more details.

<!-- Iâ€™m Neeraja Kirtane, a second-year Masterâ€™s student in Computer Science at the University of Illinois Urbana-Champaign (UIUC), advised by [Prof. Hao Peng](https://haopeng-nlp.github.io/) and [Prof. Dilek Hakkani-TÃ¼r](https://siebelschool.illinois.edu/about/people/all-faculty/dilek).

My research focuses on making natural language processing (NLP) models more trustworthy and interpretable. Recently, I worked on preemptively detecting and mitigating hallucinations in large language models (LLMs) by analyzing their hidden states [paper link](https://arxiv.org/pdf/2410.02899). I am also exploring methods for jailbreaking LLMs to generate harmful content and developing strategies to counteract such vulnerabilities [paper link](https://arxiv.org/pdf/2501.14073).

Prior to UIUC, I was a Post-Baccalaureate Research Fellow at the Robert Bosch Centre for Data Science and AI [(RBCDSAI)](https://rbcdsai.iitm.ac.in/) at IIT Madras, where I was advised by [Prof. Balaraman Ravindran](https://dsai.iitm.ac.in/~ravi/) There, I developed automated machine learning tools to generate Wikipedia biographies for notable women in STEM.

I am currently seeking full-time opportunities in the areas of AI safety, robustness, and trustworthy machine learning.

If you are interested in my work or would like to collaborate, feel free to reach out via via [Email](kirtane.neeraja@gmail.com) or [LinkedIn](https://www.linkedin.com/in/neeraja-kirtane-16353b2a/). You can also view my [CV](https://neeraja1504.github.io/files/NeerajaKiranKirtane_CV_2025_Jan.pdf) for more details. -->


<!-- I am Neeraja Kirtane. I am a second-year [MSCS](https://cs.illinois.edu/academics/graduate/ms-program) student at the University of Illinois Urbana Champaign. I am currently advised by [Prof. Hao Peng](https://haopeng-nlp.github.io/) and closely collaborating with [Prof. Dilek Hakkani-TÃ¼r](https://siebelschool.illinois.edu/about/people/all-faculty/dilek). My current research interests lie in making NLP models trustworthy and interpretable. Recently I worked on preemptively detecting and mitigating hallucinations in LLMs by analysing the hidden states of the model [(link)](https://arxiv.org/pdf/2410.02899). I am also working on jailbreaking LLMs to produce harmful content [(link)](https://arxiv.org/pdf/2501.14073).
<br>

Previously, I was a Post Baccalaureate fellow at the Robert Bosch Centre for Data Science and AI [RBCDSAI](https://rbcdsai.iitm.ac.in/), IITM Chennai. I was advised by [Prof. Balaraman Ravindran](https://dsai.iitm.ac.in/~ravi/) and worked on building automated ML tools to generate wikipedia biographies for notable women in STEM. I completed my undergraduate studies in Computer Science and Engineering from Manipal Institute of Technology in Manipal, Karnataka, India.
<br>

<!-- I worked with Prof. Balaraman Ravindran and Dr Rajashree Baskaran on the project [Hidden Voices](https://hidden-voices.github.io/). This is an open-source project with the initial goal of building intelligent tools to aid in adding 10,000 women's biography drafts to Wikipedia. It aims to make a positive impact on gender representation among digital sources and to reduce the gender data gap. Previously in my undergraduate studies, I have worked on finding out occupational stereotypes and mitigating the gender bias in Hindi and Marathi language models. -->


<!-- If you like my work or want to collaborate with me, you can get in touch with me via [Email](kirtane.neeraja@gmail.com) or [LinkedIn](https://www.linkedin.com/in/neeraja-kirtane-16353b2a/). Check out my work in my [CV](https://neeraja1504.github.io/files/NeerajaKiranKirtane_CV_2025_Jan.pdf)
<br>

I am looking for job opportunities in AI safety applications. If you feel I am a right fit, please contact me. --> 

<!-- I am looking for PhD positions in NLP for Fall 2025. If you feel I am a right fit, please contact me.  -->

<!-- I am Neeraja Kirtane, a final year undergrad student at Manipal Institute of Technology, Manipal. Currently I am interning at the Robert Bosch Centre for Data Science and Artifical Intelligence(RBCDSAI) at IIT Chennai, where I am working on graph DL. I am very passionate about Technology and Maths and love to learn new things. Previously I have worked on finding and mitigating gender bias from text data. I have specifically worked in Hindi and Marathi languages to address this gender bias issue. I strongly believe that technology should not be just restricted to English speakers and should be available to all. Also, these systems should be free from bias of all forms. My research interests lie in NLP and Graph Deep Learning. I am specifically interested in Fairness in NLP as well working on low resource and gendered languages in NLP. I believe in socially aware and ethically responsible AI systems. \
If you like my work or want to collaborate with me, you can get in touch with me via [Email](kirtane.neeraja@gmail.com) or [LinkedIn](https://www.linkedin.com/in/neeraja-kirtane-16353b2a/) --> 

<!-- Hello, I'm am currently a student at [Georgia Institute of Technology](https://www.gatech.edu/) pursuing my [MS in Computer Science](https://www.cc.gatech.edu/degree-programs/master-science-computer-science). I completed my undergraduate studies in Computer and Communication Engineering at [Manipal Institute of Technology](https://manipal.edu/mit.html) in Manipal, Karnataka, India. 
<br>

My research interests are in the field of Computer Vision, Continual Learning, Zero-Shot Learning, Semi/Self-supervised Learning and NLP. Solving deep learning problems using a limited (ideally zero) amount of data is what piques my interest. 
<br>

Prior to this I have worked as a research assistant at the Aritificial Intelligence and Robotics Lab, Indian Institute of Science, Bangalore, India in the field of Continual Zero-Shot Learning. I have also worked as a AI Developer at Project MANAS working on their self-driving car and later as a AI Researcher at Research Society Manipal where I primarily worked in developing AI solutions in low resource scenarios. 
<br>

During my free time I try to stream research paper explanations on my [YouTube channel](https://youtube.com/c/SahilKhose). 
The [Talks section](https://sahilkhose.github.io/talks/) include the explanations presented by me.
The [Feed section](https://sahilkhose.github.io/feed/) **[New]** includes some of the ideas I find interesting across the web. 
<br>

I am always open to research collaborations, so if you want to discuss projects that I have worked on or a potential collaboration, feel free to drop a mail at sahil(dot)khose(at)gatech(dot)edu. Check out my work in my [CV](https://sahilkhose.github.io/files/Sahil_Khose.pdf).  -->


---
<!-- ## Recent Updates
[ ðŸŒŸ: Important | ðŸ’¡: Research Paper | ðŸŽ¬: YouTube Video | ðŸ“†: Miscellaneous ]

- ðŸŒŸ Aug 22, 2022: I begin my graduate studies at Georgia Tech. Hoping to reach new limits. 

- ðŸ’¡ Jun 23, 2022: Our paper - [An Efficient Modern Baseline for FloodNet VQA](https://arxiv.org/abs/2205.15025) is accepted in the [New In ML workshop](https://ablacan.github.io/NewInML2022_ICML/) at ICML 2022! [ðŸŒŸ Update: Best Paper Award!]

- ðŸ’¡ Apr 5, 2022: Our paper - [Transformer based ensemble for emotion detection](https://arxiv.org/abs/2203.11899) is accepted in the [WASSA workshop](https://wassa-workshop.github.io/) at ACL 2022!

- ðŸŒŸ Apr 4, 2022: Admitted to the [MS CS](https://www.cc.gatech.edu/degree-programs/master-science-computer-science) program of [Georgia Tech](https://www.gatech.edu/) for Fall 2022!

- ðŸ’¡ Mar 22, 2022: Our pre-print - [Transformer based ensemble for emotion detection](https://arxiv.org/abs/2203.11899) is made public on arxiv.

- ðŸŽ¬ Feb 4, 2022: Released our 18th stream on YouTube, having [Ankita Ghosh](https://ankitaghosh9.github.io/) present to us her amazing paper titled [IS-CAM: Integrated Score-CAM for axiomatic-based explanations](https://www.youtube.com/watch?v=26X-HoPCD1Y).

-  ðŸŽ¬	Jan 30, 2022: Released our 17th stream on YouTube - a amazing paper on [Open World Object Detection](https://www.youtube.com/watch?v=UKX93Yd1o-8).

- ðŸ“† Oct 25, 2021: Adding another [feed blog](https://sahilkhose.github.io/feed/) answering the question - What is the most beautiful idea about Deep Learning?

- ðŸ’¡	Oct 23, 2021: Our paper - [Semi-Supervised Classification and Segmentation on High Resolution Aerial Images](https://arxiv.org/abs/2105.08655) is accepted in the [Tackling Climate Change with ML workshop](https://www.climatechange.ai/events/neurips2021.html) at NeurIPS 2021! ðŸŒŸAll 3 papers accepted in various workshops at NeurIPS 2021!ðŸŒŸ

- ðŸ’¡	Oct 21, 2021: Our paper - [XCI-Sketch: Extraction of Color Information from Images for Generation of Colored Outlines and Sketches](https://arxiv.org/abs/2108.11554) is accepted in the 1. ML for Creativity and Design, 2. Deep Generative Models and Downstream Applications, 3. CtrlGen: Controllable Generative Modeling in Language and Vision, and 4. New in ML workshop at NeurIPS 2021! 

- ðŸ’¡	Oct 18, 2021: Our paper - [A Studious Approach to Semi-Supervised Learning](https://arxiv.org/abs/2109.08924) is accepted in the [ICBINB workshop](https://i-cant-believe-its-not-better.github.io/neurips2021/) at NeurIPS 2021!

- ðŸ“†	Oct 11, 2021: Added a [Feed section](https://sahilkhose.github.io/feed/) to share interesting insights and ideas that I come across. (Go read it!)

-  ðŸŽ¬	Oct 2, 2021: Released our 16th stream on YouTube - a amazing paper on [Zero-Shot Object Detection (BLC)](https://www.youtube.com/watch?v=JP6SjoLDrkc).

- ðŸ’¡	Sep 18, 2021: Our pre-print - [A Studious Approach to Semi-Supervised Learning](https://arxiv.org/abs/2109.08924) is made public on arxiv.

- ðŸŽ¬	Sep 12, 2021: Released our 15th stream on YouTube - very recent Google Research paper [FLAN: Finetuned Language Models are Zero-Shot Learners](https://www.youtube.com/watch?v=QDeYaqdjH0w).

- ðŸŽ¬	Sep 05, 2021: Released our 14th stream on YouTube - a amazing paper on [Self-Distillation](https://www.youtube.com/watch?v=ugvHJbzhod8).

- ðŸ“†	Sep 03, 2021: Fruitpunch AI Hyderabad chapter is made public on [LinkedIn](https://www.linkedin.com/feed/update/urn:li:activity:6839531104295235584/). I am leading the team as the AI Expertise Head.

- ðŸ“†	Aug 30, 2021: Published my second blog on [Medium](https://sahilkhose.medium.com/zero-shot-learning-the-seen-the-unseen-and-the-unknown-9e69da125df2) explaining a fundamental concept of Zero-Shot Learning.

- ðŸŽ¬	Aug 29, 2021: Released our 13th stream on YouTube, having Shruti Jain present to us a amazing paper on [Zero-Shot Object Detection](https://www.youtube.com/watch?v=f-UELOTXlB4).


- ðŸ’¡ Aug 26, 2021: Our pre-print - [XCI-Sketch: Extraction of Color Information from Images for Generation of Colored Outlines and Sketches](https://arxiv.org/abs/2108.11554) is made public on arxiv. -->
