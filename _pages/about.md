---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
I’m Neeraja Kirtane, my research is focused on building trustworthy and interpretable language models. My work lies at the intersection of AI safety, robustness, and interpretability, with the goal of making large language models (LLMs) more reliable and transparent. 

I’m currently a Research Engineer at **[MathGPT.ai](https://mathgpt.ai)**, where I’m developing education-centric reasoning benchmarks to evaluate reasoning robustness in state-of-the-art models. My [work](https://arxiv.org/pdf/2510.06430?) explores how simple linguistic or contextual changes can destabilize model reasoning — and how fine-tuning small language models (SLMs) can improve their consistency and usefulness in AI tutoring and educational applications.

Alongside this, I am working under the supervision of **[Prof. Kuan-Hao Huang](https://khhuang.me/)** at Texas A&M University to probe reasoning and multilingual generalization in LLMs. Using interpretability tools such as neuron activation analysis and feature attribution, we are studying how models encode reasoning processes across languages and how these representations transfer between linguistic systems.

Before this, I completed my M.S. in Computer Science at the University of Illinois Urbana–Champaign (UIUC), where I was advised by [Prof. Hao Peng](https://haopeng-nlp.github.io/) and [Prof. Dilek Hakkani-Tür](https://siebelschool.illinois.edu/about/people/all-faculty/dilek).
At UIUC, I worked on projects aimed at improving trust and accountability in LLMs:

- **[FactCheckmate](https://arxiv.org/pdf/2410.02899)** – a framework for preemptively detecting and mitigating hallucinations in LLMs by analyzing their hidden-state dynamics and identifying early indicators of factual inconsistency.

- **[Jailbreaking LLMs](https://arxiv.org/pdf/2501.14073)** – a study of scientific-sounding adversarial prompts that can elicit biased or toxic model responses, revealing deeper vulnerabilities in instruction-following and safety alignment.


Previously, I worked as a Research Assistant at IIT Madras under [Prof. Balaraman Ravindran](http://www.cse.iitm.ac.in/~ravi/) and [Dr. Ashish Tendulkar](https://www.linkedin.com/in/ashishtendulkar/?originalSubdomain=in)

<!-- I’m **Neeraja Kirtane**, a recent **MSCS graduate** from the University of Illinois Urbana-Champaign (UIUC), where I was advised by [Prof. Hao Peng](https://haopeng-nlp.github.io/) and [Prof. Dilek Hakkani-Tür](https://siebelschool.illinois.edu/about/people/all-faculty/dilek).

My research focuses on building **trustworthy and interpretable NLP systems**. At UIUC, I worked on:

- **[FactCheckmate](https://arxiv.org/pdf/2410.02899)**: Preemptively detecting and mitigating hallucinations in large language models (LLMs) by analyzing their hidden states.
- **[Jailbreaking LLMs](https://arxiv.org/pdf/2501.14073)**: Designing scientific-sounding prompts that elicit biased or toxic responses from LLMs, revealing vulnerabilities in instruction following.

Currently, I am:
- Collaborating with **[Prof. Kuan-Hao Huang](https://khhuang.me/)** (Texas A&M University) on probing reasoning in **multilingual LLMs** using interpretability tools.
- Interning at **[MathGPT.ai](https://mathgpt.ai)**, where I’m developing a **benchmark** to evaluate the reasoning robustness of SOTA models and fine-tuning **small language models (SLMs)** for AI tutoring needs and applications.

Previously, I was a **Post-Baccalaureate Research Fellow** at the [Robert Bosch Centre for Data Science and AI (RBCDSAI)](https://rbcdsai.iitm.ac.in/) at **IIT Madras**, advised by [Prof. Balaraman Ravindran](http://www.cse.iitm.ac.in/~ravi/), where I built intelligent tools to generate Wikipedia biographies for women in STEM. -->

I’m currently seeking **PhD opportunities** or **full-time research roles** in _AI safety, robustness, and interpretability_.

If you’re interested in my work or would like to collaborate, feel free to reach out via [Email](mailto:kirtane3@illinois.edu) or [LinkedIn](https://www.linkedin.com/in/neeraja-kirtane-16353b2a/). You can also view my [CV](neeraja1504/neeraja1504.github.io/files/NeerajaKiranKirtane_CV_Nov_2025.pdf) for more details.

<!-- I’m Neeraja Kirtane, a second-year Master’s student in Computer Science at the University of Illinois Urbana-Champaign (UIUC), advised by [Prof. Hao Peng](https://haopeng-nlp.github.io/) and [Prof. Dilek Hakkani-Tür](https://siebelschool.illinois.edu/about/people/all-faculty/dilek).

My research focuses on making natural language processing (NLP) models more trustworthy and interpretable. Recently, I worked on preemptively detecting and mitigating hallucinations in large language models (LLMs) by analyzing their hidden states [paper link](https://arxiv.org/pdf/2410.02899). I am also exploring methods for jailbreaking LLMs to generate harmful content and developing strategies to counteract such vulnerabilities [paper link](https://arxiv.org/pdf/2501.14073).

Prior to UIUC, I was a Post-Baccalaureate Research Fellow at the Robert Bosch Centre for Data Science and AI [(RBCDSAI)](https://rbcdsai.iitm.ac.in/) at IIT Madras, where I was advised by [Prof. Balaraman Ravindran](https://dsai.iitm.ac.in/~ravi/) There, I developed automated machine learning tools to generate Wikipedia biographies for notable women in STEM.

I am currently seeking full-time opportunities in the areas of AI safety, robustness, and trustworthy machine learning.

If you are interested in my work or would like to collaborate, feel free to reach out via via [Email](kirtane.neeraja@gmail.com) or [LinkedIn](https://www.linkedin.com/in/neeraja-kirtane-16353b2a/). You can also view my [CV](https://neeraja1504.github.io/files/NeerajaKiranKirtane_CV_2025_Jan.pdf) for more details. -->


<!-- I am Neeraja Kirtane. I am a second-year [MSCS](https://cs.illinois.edu/academics/graduate/ms-program) student at the University of Illinois Urbana Champaign. I am currently advised by [Prof. Hao Peng](https://haopeng-nlp.github.io/) and closely collaborating with [Prof. Dilek Hakkani-Tür](https://siebelschool.illinois.edu/about/people/all-faculty/dilek). My current research interests lie in making NLP models trustworthy and interpretable. Recently I worked on preemptively detecting and mitigating hallucinations in LLMs by analysing the hidden states of the model [(link)](https://arxiv.org/pdf/2410.02899). I am also working on jailbreaking LLMs to produce harmful content [(link)](https://arxiv.org/pdf/2501.14073).
<br>

Previously, I was a Post Baccalaureate fellow at the Robert Bosch Centre for Data Science and AI [RBCDSAI](https://rbcdsai.iitm.ac.in/), IITM Chennai. I was advised by [Prof. Balaraman Ravindran](https://dsai.iitm.ac.in/~ravi/) and worked on building automated ML tools to generate wikipedia biographies for notable women in STEM. I completed my undergraduate studies in Computer Science and Engineering from Manipal Institute of Technology in Manipal, Karnataka, India.
<br>

<!-- I worked with Prof. Balaraman Ravindran and Dr Rajashree Baskaran on the project [Hidden Voices](https://hidden-voices.github.io/). This is an open-source project with the initial goal of building intelligent tools to aid in adding 10,000 women's biography drafts to Wikipedia. It aims to make a positive impact on gender representation among digital sources and to reduce the gender data gap. Previously in my undergraduate studies, I have worked on finding out occupational stereotypes and mitigating the gender bias in Hindi and Marathi language models. -->


<!-- If you like my work or want to collaborate with me, you can get in touch with me via [Email](kirtane.neeraja@gmail.com) or [LinkedIn](https://www.linkedin.com/in/neeraja-kirtane-16353b2a/). Check out my work in my [CV](https://neeraja1504.github.io/files/NeerajaKiranKirtane_CV_2025_Jan.pdf)
<br>

I am looking for job opportunities in AI safety applications. If you feel I am a right fit, please contact me. --> 

<!-- I am looking for PhD positions in NLP for Fall 2025. If you feel I am a right fit, please contact me.  -->

<!-- I am Neeraja Kirtane, a final year undergrad student at Manipal Institute of Technology, Manipal. Currently I am interning at the Robert Bosch Centre for Data Science and Artifical Intelligence(RBCDSAI) at IIT Chennai, where I am working on graph DL. I am very passionate about Technology and Maths and love to learn new things. Previously I have worked on finding and mitigating gender bias from text data. I have specifically worked in Hindi and Marathi languages to address this gender bias issue. I strongly believe that technology should not be just restricted to English speakers and should be available to all. Also, these systems should be free from bias of all forms. My research interests lie in NLP and Graph Deep Learning. I am specifically interested in Fairness in NLP as well working on low resource and gendered languages in NLP. I believe in socially aware and ethically responsible AI systems. \
If you like my work or want to collaborate with me, you can get in touch with me via [Email](kirtane.neeraja@gmail.com) or [LinkedIn](https://www.linkedin.com/in/neeraja-kirtane-16353b2a/) --> 





